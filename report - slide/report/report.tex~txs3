\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{vietnam}
\usepackage{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{makecell}
\usepackage{array}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{mdframed}
\usepackage{fontawesome}
\usepackage{tikz}
\usepackage{setspace}
\usetikzlibrary{patterns}
\usetikzlibrary{calc,angles}
\usepackage[left= 2cm, right = 2cm, top = 2cm, bottom = 2cm]{geometry}
\usepackage{scalefnt}
\usepackage{fancybox}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{pgfplots}
\usepackage{longtable}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{color} % tô màu cho code
\usepackage{setspace}
\usepackage{tabularx}
% Đặt giãn dòng cho toàn bộ tài liệu
\renewcommand{\baselinestretch}{1.3} % Giãn dòng 
\pagestyle{fancy}
\fancyhf{}
%\renewcommand{\baselinestretch}{1.5} % Giãn dòng 
%\fancyhead[LE,RO]{\textsl{\leftmark }}
\fancyhead[R]{\leftmark}
\fancyfoot[C]{Trang \thepage}

\renewcommand{\footrulewidth}{0.4pt}
\renewcommand{\headrulewidth}{0.4pt}

\newmdenv[linewidth=0.6pt,linecolor=blue,skipabove=\topsep,skipbelow=\topsep,
leftmargin=-5pt,rightmargin=-5pt,
innerleftmargin=5pt,innerrightmargin=5pt]{mybox}
\setlist{nolistsep}
\newcommand\tab[1][0.7cm]{\hspace*{#1}}
\pagenumbering{arabic}
\clearpage   
\thispagestyle {empty}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}



\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\lstset{frame=tb,
	language=verilog,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	backgroundcolor=\color{backcolour},
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3,
	numbers=left,                    
	numbersep=5pt
}




\begin{document}
\begin{titlepage}
		\begin{tikzpicture}[overlay,remember picture]
			\draw [line width=3pt]
			($ (current page.north west) + (2.5cm,-2.5cm) $)
			rectangle
			($ (current page.south east) + (-2.5cm,2.5cm) $);
			\draw [line width=0.5pt]
			($ (current page.north west) + (2.6cm,-2.6cm) $)
			rectangle
			($ (current page.south east) + (-2.6cm,2.6cm) $); 
		\end{tikzpicture}
		
	\begin{center}
		\textbf{ĐẠI HỌC QUỐC GIA THÀNH PHỐ HỒ CHÍ MINH} \\
		TRƯỜNG ĐẠI HỌC BÁCH KHOA \\
		KHOA ĐIỆN - ĐIỆN TỬ \\
		\textbf{BỘ MÔN VIỄN THÔNG}\\
		---------------o0o---------------\\
	\end{center}
	\vspace{0.5cm}
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.3]{images/Pic_88} 
	\end{figure}

	\begin{center}
		\begin{tabular}{c}
			\textbf{{\Large ĐỒ ÁN TỐT NGHIỆP}}\\ \\
				\textbf{{\Large ĐỀ TÀI:}}\\ \\
			\textbf{{\Large NHẬN DIỆN BIỂN BÁO GIAO THÔNG TRÊN FPGA}} \\ \\

		\end{tabular}
	\end{center}

	\vspace{2cm}
	\begin{table}[h]
		\begin{center}
		
		\begin{tabular}{rrl}
			\hspace {5.6cm}
						& { \bf GVHD : } & { \bf  TS. VÕ QUẾ SƠN} \\
						& { \bf SVTH : } & { \bf  HUỲNH THỊNH PHÁT} \\
						& { \bf MSSV : } & { \bf  2114369} \\
						\end{tabular}
					\end{center}
	\end{table}

	\vspace{3cm}
	\begin{center}
		{\footnotesize \large \textbf {Tp. Hồ Chí Minh, 25/04/2025}}
	\end{center}
\end{titlepage}
\begin{center}
	\section*{LỜI NÓI ĐẦU}
\end{center}
%\begin{center} \textbf{PHÂN CÔNG LÀM VIỆC} \end{center}

\addcontentsline{toc}{section}{Lời nói đầu}
\noindent Trong bối cảnh công nghệ phát triển mạnh mẽ hiện nay, các hệ thống giao thông thông minh ngày càng trở thành một yếu tố quan trọng trong việc đảm bảo an toàn và hiệu quả cho người tham gia giao thông. Một trong những ứng dụng then chốt của hệ thống giao thông thông minh là nhận diện biển báo giao thông. Việc phát triển hệ thống nhận diện biển báo giao thông tự động không chỉ giúp nâng cao mức độ an toàn mà còn góp phần cải thiện hiệu quả giao thông trong các thành phố lớn. \\

\noindent Với mong muốn đóng góp vào sự phát triển của các ứng dụng trong lĩnh vực giao thông thông minh, em lựa chọn đề tài "Nhận diện biển báo giao thông bằng FPGA PYNQ-Z2". Đề tài này tập trung vào việc nghiên cứu và ứng dụng nền tảng FPGA PYNQ-Z2 để xây dựng một hệ thống nhận diện biển báo giao thông hiệu quả, sử dụng các phương pháp tối ưu cho xử lý hình ảnh và phân loại biển báo. \\

\noindent PYNQ-Z2 là một nền tảng mạnh mẽ, hỗ trợ các công cụ và tài nguyên cần thiết để thiết kế và triển khai các ứng dụng vi mạch số. Đề tài này sẽ giới thiệu các phương pháp và thuật toán để nhận diện biển báo giao thông trên FPGA, từ đó đánh giá và tối ưu các giải pháp về hiệu suất, chi phí và độ chính xác của hệ thống. \\

\noindent Em xin gửi lời cảm ơn chân thành đến thầy Võ Quế Sơn vì đã nhiệt tình hướng dẫn và hỗ trợ em trong suốt quá trình thực hiện đề tài này. Nhờ sự giúp đỡ tận tâm của thầy, em đã có thể hoàn thành đề tài và hy vọng rằng kết quả nghiên cứu sẽ góp phần vào sự phát triển của các hệ thống giao thông thông minh trong tương lai. \\

	\vspace{3cm}
	\begin{table}[h]
	\begin{center}
				\begin{tabular}{rrl}
			\hspace {5.6cm}
			&  { \bf  TP. Hồ Chính Minh, ngày 25 tháng 5 năm 2025} \\
		\end{tabular}
			\begin{tabular}{rrl}
			\vspace{1cm}	
		\hspace {5.6cm}
		&  { \bf Huỳnh Thịnh Phát} \\
	\end{tabular}
	\end{center}
\end{table}

\newpage

\begin{center}
	\section*{TÓM TẮT ĐỒ ÁN}
\end{center}
%\begin{center} \textbf{LỜI MỞ ĐẦU} \end{center}

\addcontentsline{toc}{section}{Tóm tắt đồ án}

\newpage
\tableofcontents
\newpage
{\let\oldnumberline\numberline
	\renewcommand{\numberline}{\tablename~\oldnumberline}
	\listoftables
	\addcontentsline{toc}{section}{Danh sách bảng}
}
\newpage
{\let\oldnumberline\numberline
	\renewcommand{\numberline}{\figurename~\oldnumberline}
	\listoffigures}
\addcontentsline{toc}{section}{Danh sách hình vẽ}
\newpage 


\begin{center} \textbf{ĐỒ ÁN TỐT NGHIỆP - CHUYÊN NGÀNH ĐIỆN TỬ VIỄN THÔNG} \end{center}
\section{Giới thiệu về nền tảng FPGA và kit PYNQ Z2}
\subsection{Tổng quan về FPGA}
FPGA (Field-Programmable Gate Array) là một loại mạch tích hợp có thể lập trình lại sau khi sản xuất, cho phép người dùng thiết kế phần cứng tùy chỉnh cho các ứng dụng cụ thể. FPGA bao gồm các khối logic có thể cấu hình (CLBs - Configurable Logic Blocks) và các đường truyền có thể lập trình (Programmable Interconnects), giúp người thiết kế kết nối các khối logic và cấu hình chúng để thực hiện các phép toán từ các cổng logic đơn giản đến các chức năng phức tạp. Một trong những ưu điểm nổi bật của FPGA là khả năng xử lý song song, giúp thực hiện các tác vụ tính toán nhanh chóng và hiệu quả hơn so với các bộ xử lý truyền thống.\\

\noindent Các FPGA hiện nay thường được sử dụng trong nhiều ứng dụng khác nhau, đặc biệt là trong các hệ thống xử lý tín hiệu, hình ảnh và các thuật toán học máy. FPGA có thể lập trình lại nhiều lần, giúp người dùng linh hoạt thay đổi chức năng của mạch mà không cần thay thế phần cứng. Tuy nhiên, thiết kế FPGA yêu cầu kiến thức sâu về các ngôn ngữ mô tả phần cứng như VHDL hoặc Verilog, điều này làm cho việc phát triển phần cứng trên FPGA có phần phức tạp hơn so với lập trình phần mềm.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.65]{images/pic7} 
	\caption{Thiết kế FPGA}
\end{figure} 
\newpage
\subsection{Ưu điểm của FPGA}
Dưới đây là một số lợi ích của FPGA:
\begin{itemize}
	 
\item Xử lý song song: FPGA có khả năng thực hiện các phép toán song song, giúp tăng tốc các tác vụ tính toán nặng như xử lý tín hiệu số và học máy.

\item Linh hoạt: FPGA có thể được lập trình lại bất kỳ lúc nào, giúp người dùng thay đổi chức năng của nó mà không phải thay phần cứng. Điều này giúp tiết kiệm chi phí và thời gian phát triển.

\item Hiệu suất cao: FPGA có thể xử lý các tác vụ phức tạp với hiệu suất cao, nhờ vào khả năng tối ưu hóa phần cứng cho từng ứng dụng cụ thể.

\item Tiết kiệm chi phí: So với ASIC (mạch tích hợp dành riêng), FPGA có chi phí thấp hơn trong việc phát triển và không cần phải chi tiền cho việc thiết kế phần cứng riêng biệt.

\item Dễ dàng lập trình: FPGA có thể được lập trình thông qua phần mềm sử dụng các ngôn ngữ như VHDL hoặc Verilog, giúp dễ dàng thiết kế và kiểm tra các hệ thống phần cứng.
\end{itemize}

\subsection{Nhược điểm của FPGA}
Dưới đây là một số hạn chế của FPGA:
\begin{itemize}

\item Yêu cầu kiến thức phần cứng: Để lập trình FPGA, người phát triển cần có kiến thức về các ngôn ngữ mô tả phần cứng như VHDL hoặc Verilog, điều này đòi hỏi thời gian học hỏi và làm quen.

\item Tiêu thụ điện năng: FPGA có thể tiêu tốn nhiều năng lượng hơn so với các bộ xử lý chuyên dụng như ASIC hoặc GPU.

\item Giới hạn về tài nguyên: Khi chọn một FPGA cho một dự án, người phát triển phải làm việc với tài nguyên của FPGA đã chọn, và đôi khi phải tìm cách tối ưu hóa tài nguyên hạn chế này.

\item Đắt khi sản xuất số lượng lớn: FPGA thích hợp với prototyping (thử nghiệm mẫu) và sản xuất số lượng nhỏ, nhưng khi cần sản xuất số lượng lớn, chi phí cho FPGA sẽ cao hơn so với các giải pháp ASIC.
	 
\end{itemize}

\subsection{Ứng dụng của FPGA}
FPGA được sử dụng trong rất nhiều lĩnh vực và ứng dụng, từ các hệ thống đơn giản đến các cấu trúc phức tạp. Những ứng dụng tiêu biểu của FPGA bao gồm:
\begin{itemize}
	
\item Phát triển phần cứng cho vi điều khiển: FPGA có thể được sử dụng để phát triển các bo mạch phát triển và giao diện cho các vi điều khiển, giúp các nhà thiết kế dễ dàng thử nghiệm và phát triển sản phẩm.

\item Tự động hóa và IoT (Internet of Things): FPGA được ứng dụng trong các hệ thống điều khiển và tự động hóa, đặc biệt trong các thiết bị IoT để xử lý dữ liệu nhanh chóng và hiệu quả.

\item Thị giác máy tính và xử lý hình ảnh: FPGA là một công cụ lý tưởng cho các ứng dụng xử lý hình ảnh và video nhờ vào khả năng xử lý song song và hiệu suất cao.

\item Mã hóa và bảo mật: FPGA được sử dụng trong các hệ thống mã hóa dữ liệu, đặc biệt là trong các ứng dụng đòi hỏi tốc độ xử lý cao và bảo mật.

\item Ứng dụng trong hàng không và quốc phòng: Các hệ thống trên FPGA có thể đáp ứng được yêu cầu khắt khe trong ngành hàng không và quốc phòng, nơi mà tính linh hoạt và hiệu suất là rất quan trọng.
	
\end{itemize}

\subsection{Tổng quan về kit PYNQ-Z2}
PYNQ-Z2 là một nền tảng học tập và nghiên cứu vi mạch số (FPGA) hiệu quả, kết hợp phần cứng FPGA mạnh mẽ của Xilinx với phần mềm Python linh hoạt. PYNQ-Z2 cung cấp cho người dùng môi trường lập trình trực quan, dễ sử dụng, cho phép họ thiết kế, mô phỏng và triển khai các vi mạch số một cách nhanh chóng và hiệu quả.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{images/pic1} 
	\caption{Hình ảnh kit PYNQ-Z2}
\end{figure} 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{images/pic2} 
	\caption{Thông số kỹ thuật kit PYNQ-Z2}
\end{figure} 
\newpage
\subsection{Cách kết nối kit PYNQ-Z2}
\textbf {Chuẩn bị:}
\begin{itemize}
	\item PYNQ-Z2 board
	\item Máy tính có sẵn trình duyệt thông dụng
	\item Dây cáp Ethernet 
	\item Dây mirco USB
	\item 1 thẻ SD đã được tải Image có OS cấu hình sẵn.
	Ta download image từ web "pynq.io" và sử dụng "Win32DiskImager utility" để chèn image OS vào thẻ SD.
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.5]{images/pic3} 
		\caption{Chèn image OS vào thẻ SD}
	\end{figure} 
\end{itemize}

\textbf{Tiến hành Setup:} 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{images/pic4} 
	\caption{Hình ảnh kết nối kit PYNQ-Z2}
\end{figure} 

\noindent Ta thực hiện các kết nối Micro USB, Ethernet, thẻ SD và gắn các jumpers nguồn và SD theo hình ảnh trên. \\
\newpage
\noindent Bật nguồn kit và mở cửa sổ Network and Sharing Center, set lại địa chỉ IP và DNS theo hướng dẫn sau:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.35]{images/pic5} 
	\caption{Set IP và DNS cho kit}
\end{figure} \\
Sau khi set địa chỉ IP và DNS cho kit ta đợi khoảng 1 phút cho đến khi đèn "DONE" màu vàng sáng, sau đó 2 LED RCB chớp nháy, 4 LED TỪ 0-3 sẽ sáng đèn. Khi này ta đã kết nối kit với PC thành công.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{images/pic6} 
	\caption{Hình ảnh kit đã kết nối thành công}
\end{figure} 
\newpage 
\section{Lý thuyết}
\subsection{Giới thiệu về mô hình học sâu (Deep Learning Models)}
Mô hình học sâu (Deep Learning - DL) là một nhánh con của học máy (machine learning), được phát triển dựa trên các mạng nơ-ron nhân tạo (artificial neural networks). Các mô hình học sâu được gọi là "sâu" vì chúng sử dụng nhiều lớp ẩn (hidden layers) để trích xuất các đặc trưng phức tạp từ dữ liệu. Mô hình học sâu có khả năng học từ dữ liệu một cách tự động mà không cần phải xác định trước các đặc trưng quan trọng, điều này giúp chúng đặc biệt mạnh mẽ trong việc xử lý các vấn đề phức tạp như nhận diện hình ảnh, xử lý ngôn ngữ tự nhiên, nhận dạng tiếng nói và nhiều ứng dụng khác. \\

\noindent Một trong những yếu tố quan trọng giúp học sâu trở nên mạnh mẽ là khả năng học được các biểu diễn dữ liệu phức tạp thông qua việc truyền dữ liệu qua các lớp khác nhau trong mô hình. Học sâu đã giúp đạt được những bước tiến đáng kể trong nhiều lĩnh vực, nhưng cũng có những thách thức về yêu cầu tính toán và tài nguyên bộ nhớ khi triển khai trên các thiết bị có hạn chế tài nguyên, chẳng hạn như các thiết bị di động hoặc hệ thống nhúng.
\subsection{Giới thiệu về Convolutional Neural Networks - CNN}
Mạng Convolutional (Convolutional Neural Networks - CNN) là một trong những mô hình học sâu thành công nhất, đặc biệt trong việc xử lý hình ảnh và video. CNN được thiết kế để nhận diện các đặc trưng không gian trong dữ liệu có cấu trúc như ảnh hoặc video. CNN sử dụng các lớp convolutional để tự động trích xuất các đặc trưng từ ảnh mà không cần phải xác định các đặc trưng thủ công, điều này làm cho CNN cực kỳ hiệu quả trong việc nhận dạng hình ảnh và đối tượng. 

\subsubsection{ Cấu trúc của CNN:}
\begin{itemize}

	\item Lớp Convolutional (Convolutional Layer):
Lớp này sử dụng các bộ lọc (filters) hoặc kernels để phát hiện các đặc trưng cơ bản trong ảnh, chẳng hạn như cạnh, góc, và các kết cấu cơ bản khác. Mỗi bộ lọc di chuyển qua toàn bộ ảnh và thực hiện phép toán convolution, tạo ra bản đồ đặc trưng (feature maps). Các bộ lọc này giúp mạng học được các đặc trưng không gian từ dữ liệu đầu vào.

	\item Lớp Pooling (Pooling Layer):

Lớp pooling có chức năng giảm độ phân giải của các bản đồ đặc trưng, đồng thời giúp giảm bớt số lượng phép toán mà không làm mất đi các đặc trưng quan trọng. Phương pháp max pooling là một trong những kỹ thuật phổ biến, trong đó giá trị lớn nhất trong mỗi vùng nhỏ của bản đồ đặc trưng được giữ lại.

	\item Lớp Fully Connected (FC Layer):

Sau khi các đặc trưng đã được trích xuất từ các lớp convolutional và pooling, lớp fully connected sẽ kết nối tất cả các đặc trưng này lại và đưa ra kết quả phân loại hoặc dự đoán. Lớp này sử dụng toàn bộ kết nối giữa các neuron trong lớp và các neuron trong lớp kế tiếp. 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.9]{images/pic9} 
	\caption{Cấu trúc CNN}
\end{figure} 
\end{itemize}
\newpage
\subsubsection{Lợi ích của CNN:}
\begin{itemize}

	\item  Khả năng học đặc trưng tự động: CNN có khả năng tự động trích xuất các đặc trưng từ dữ liệu mà không cần phải xác định trước các đặc trưng quan trọng, giúp giảm chi phí thời gian và công sức so với các phương pháp học máy truyền thống.

	\item  Tính bất biến với vị trí: Nhờ vào cấu trúc của các lớp convolutional, CNN có khả năng nhận diện các đối tượng trong ảnh dù chúng xuất hiện ở vị trí nào, giúp cải thiện độ chính xác trong nhận diện.

	\item  Giảm yêu cầu tính toán: Bằng cách sử dụng chuyển giao trọng số (weight sharing) trong các lớp convolutional, CNN giúp giảm số lượng tham số cần học, giúp tiết kiệm bộ nhớ và tăng tốc độ tính toán. 

\end{itemize}
\subsubsection{Ứng dụng của CNN:}

\noindent CNN đặc biệt hữu ích trong các bài toán nhận diện hình ảnh và video. Các ứng dụng điển hình bao gồm:
\begin{itemize}
\item Phân loại hình ảnh: Ví dụ, phân loại ảnh thành các nhóm như chó, mèo, hoặc nhận diện các vật thể cụ thể trong ảnh, video.

\item Nhận diện khuôn mặt trong các hệ thống bảo mật.

\item Nhận diện biển báo giao thông trong các hệ thống giao thông thông minh.
\end{itemize}


\subsection{Giới thiệu về Binarized Neural Networks - BNN}
Mạng Nơ-ron nhị phân (Binarized Neural Networks - BNNs) là một phương pháp tối ưu hóa các mô hình học sâu (Deep Neural Networks - DNNs), với mục đích giảm thiểu yêu cầu về bộ nhớ và tính toán trong khi vẫn giữ được khả năng học mạnh mẽ của các mô hình DNN truyền thống. BNN đặc biệt hữu ích khi triển khai trên các hệ thống có tài nguyên hạn chế, chẳng hạn như các thiết bị di động, hệ thống nhúng hoặc các phần cứng như FPGA và ASIC. BNN hoạt động bằng cách nhị phân hóa cả trọng số (weights) và kích hoạt (activations) của mô hình học sâu, nghĩa là chúng chỉ sử dụng hai giá trị nhị phân (+1 hoặc -1) thay vì các giá trị thực (floating-point values). \\

\noindent Trong khi các mô hình học sâu như DNNs và CNNs có khả năng học mạnh mẽ và linh hoạt, chúng lại yêu cầu rất nhiều bộ nhớ và tài nguyên tính toán. Điều này làm cho việc triển khai các mô hình này trên các nền tảng có tài nguyên hạn chế (như IoT devices, mobile devices, hoặc edge devices) trở nên khó khăn. BNNs được phát triển để giải quyết vấn đề này, cho phép các mô hình học sâu có thể hoạt động nhanh hơn và tiết kiệm bộ nhớ bằng cách sử dụng các giá trị nhị phân thay cho các giá trị thực. \\

\noindent BNN được xây dựng dựa trên các phương pháp quy chuẩn hóa (quantization) và nhị phân hóa (binarization) trong học sâu, cho phép giảm kích thước mô hình mà không làm giảm quá nhiều độ chính xác. Các nghiên cứu về BNN đã chỉ ra rằng việc nhị phân hóa trọng số và kích hoạt có thể mang lại các lợi ích rõ rệt về hiệu suất và tiết kiệm tài nguyên trong quá trình suy luận (inference), cũng như huấn luyện (training).

\subsubsection{Các khái niệm cơ bản trong BNN}
\begin{enumerate}
	\item Trọng số (Weights): Trong BNN, trọng số là các giá trị học được và được sử dụng trong phép toán dot product với các giá trị kích hoạt từ các lớp trước. Tuy nhiên, thay vì sử dụng các giá trị thực, trọng số trong BNN được nhị phân hóa, nghĩa là chúng chỉ có thể nhận một trong hai giá trị: +1 hoặc -1. Mặc dù trong quá trình huấn luyện, các trọng số thực được sử dụng, nhưng sau khi huấn luyện xong, các trọng số nhị phân sẽ được sử dụng trong quá trình suy luận. \\
	
	\item Kích hoạt (Activations): Kích hoạt là các giá trị đầu ra của hàm kích hoạt trong mỗi neuron. Trong BNN, các giá trị kích hoạt cũng được nhị phân hóa thành +1 hoặc -1, thay vì sử dụng các giá trị thực. Hàm kích hoạt được sử dụng trong BNN là hàm sign function, có nhiệm vụ chuyển giá trị thực thành giá trị. \\
	
	\item Dot Product: Trong mạng nơ-ron, dot product là một phép toán nhân và cộng được thực hiện giữa các trọng số và các giá trị kích hoạt. BNN sử dụng các phép toán nhị phân đơn giản hơn thay vì các phép toán số học thực tế, giúp tiết kiệm bộ nhớ và tính toán. \\
	

	\item Độ lệch (Bias) và Hệ số tăng cường (Gain)
	\begin{itemize}
		\item Bias là một giá trị thêm vào trong mạng nơ-ron, giúp mô hình học được các đặc trưng tốt hơn.
		\item 	Gain là một hệ số tăng cường được học trong BNN, tương tự như bias, và nó được áp dụng sau khi thực hiện phép toán dot product giữa trọng số và kích hoạt. 
	\end{itemize}
	
	\item Topology và Architecture: Topology là cấu trúc của các lớp trong mô hình mạng nơ-ron, còn architecture đề cập đến việc bố trí các thành phần phần cứng khi triển khai mạng nơ-ron. \\
\end{enumerate}

\subsubsection{Cách BNN hoạt động}
BNN được xây dựng trên nguyên lý nhị phân hóa cả trọng số và kích hoạt. Điều này giúp giảm bớt yêu cầu bộ nhớ vì mỗi trọng số và mỗi kích hoạt chỉ cần 1 bit để lưu trữ, thay vì 32 bit như trong các mô hình DNN thông thường. Điều này làm giảm kích thước mô hình và tăng tốc độ tính toán nhờ vào các phép toán nhị phân đơn giản (cộng và nhân nhị phân).
\begin{enumerate}
	\item \textbf{ Nhị phân hóa trọng số (Binarization of Weights):} \\
	\textbf{Trọng số thực} \( W_R \) \text{ được chuyển thành trọng số nhị phân } \( W_B \) \text{ thông qua hàm sign function:}
	\[
	W_B = \text{sign}(W_R)
	\]
	Nếu trọng số thực \( W_R \geq 0 \), thì \( W_B = +1 \); nếu \( W_R < 0 \), thì \( W_B = -1 \).
	
	\begin{itemize}
		\item Tuy nhiên, trong quá trình huấn luyện, trọng số thực \( W_R \) vẫn được cập nhật thông qua các phương pháp tối ưu hóa như Stochastic Gradient Descent (SGD) hoặc Adam, còn trong suy luận, các trọng số nhị phân \( W_B \) sẽ được sử dụng.
		\item Việc tính toán gradient đối với các trọng số nhị phân thông qua backpropagation gặp khó khăn vì gradient của hàm sign bằng 0 hoặc không xác định. Để giải quyết vấn đề này, phương pháp Straight-Through Estimator (STE) được sử dụng, giúp xấp xỉ gradient của hàm sign bằng cách bỏ qua gradient của lớp hiện tại và sử dụng hàm identity:
		\[
		\frac{\partial L}{\partial W_R} = \frac{\partial L}{\partial W_B}
		\]
		\item Nhờ vào phương pháp STE, các trọng số thực \( W_R \) có thể được cập nhật trong quá trình huấn luyện mà không ảnh hưởng đến các trọng số nhị phân \( W_B \).
	\end{itemize}


\begin{figure}[h]
	\centering
	\includegraphics[scale=1.2]{images/pic10} 
	\caption{Minh họa lớp sign và Straight-Through Estimator (STE)}
\end{figure} 

	\item \textbf{ Nhị phân hóa kích hoạt (Binarization of Activations)} \\
	 Hàm sign sẽ chuyển giá trị kích hoạt thực thành các giá trị nhị phân:
	\[
	a_B = \text{sign}(a_R)
	\]
	Nếu \( a_R \geq 0 \), thì \( a_B = +1 \); nếu \( a_R < 0 \), thì \( a_B = -1 \).
	
	Trong quá trình huấn luyện, để đạt được kết quả tốt, Courbariaux et al. nhận thấy rằng cần hủy bỏ gradient trong quá trình lan truyền ngược nếu đầu vào của hàm kích hoạt quá lớn. Điều này có thể được thực hiện thông qua một hàm chỉ thị (indicator function) để đặt gradient bằng 0 nếu đầu vào của hàm kích hoạt lớn hơn một giá trị giới hạn nhất định. Cụ thể:
	\[
	\frac{\partial L}{\partial a_R} = \frac{\partial L}{\partial a_B} \times 1(|a_R| \leq 1)
	\]
	Trong đó:
	\begin{itemize}
		\item \( a_R \) là giá trị thực đầu vào hàm kích hoạt.
		\item \( a_B \) là giá trị nhị phân hóa đầu ra hàm kích hoạt.
		\item \( 1(|a_R| \leq 1) \) là hàm chỉ thị, đánh giá là 1 nếu \( |a_R| \leq 1 \), và 0 nếu ngược lại. Điều này có nghĩa là nếu giá trị đầu vào hàm kích hoạt quá lớn (ngoài phạm vi vi [-1, 1]), gradient sẽ được làm bằng 0, ngừng việc cập nhật trong quá trình lan truyền ngược.
	\end{itemize}

	Quá trình này phần lớn được khắc phục thông qua việc sử dụng STE giúp mạng có thể huấn luyện hiệu quả hơn, đồng thời giữ được tính chính xác trong suy luận nhờ vào việc bù đắp gradient của hàm kích hoạt.
\end{enumerate}


\subsubsection{Lợi ích của BNN}
\begin{itemize}
	\item Tiết kiệm bộ nhớ: Việc sử dụng 1 bit thay vì các giá trị thực 32 bit giúp giảm kích thước mô hình và tiết kiệm bộ nhớ đáng kể, đặc biệt khi triển khai trên các hệ thống có tài nguyên hạn chế như IoT devices và FPGA.
	
	\item Tăng tốc tính toán: Các phép toán nhị phân có thể thực hiện nhanh chóng và hiệu quả trên phần cứng, giúp tăng tốc độ suy luận. Các phép toán như cộng và nhân nhị phân đơn giản hơn nhiều so với các phép toán với số thực.
	
	\item Tiết kiệm năng lượng: Các phép toán nhị phân tiêu thụ ít năng lượng hơn, điều này rất quan trọng khi triển khai trên các thiết bị di động hoặc hệ thống nhúng.
\end{itemize}


\subsubsection{Hạn chế của BNN}
\begin{itemize}
	\item Giảm độ chính xác: Việc nhị phân hóa trọng số và kích hoạt có thể làm giảm độ chính xác so với các mô hình sử dụng số thực. Điều này đặc biệt dễ nhận thấy khi bài toán yêu cầu độ chính xác cao trong việc phân loại hoặc nhận diện.
	
	\item Khó khăn trong huấn luyện: Việc nhị phân hóa trong quá trình huấn luyện có thể gặp khó khăn vì các gradient từ hàm sign không thể thay đổi nhỏ. Tuy nhiên, phương pháp STE đã giúp giải quyết vấn đề này một cách hiệu quả.
\end{itemize}

\subsubsection{Ứng dụng của BNN}
BNN rất thích hợp cho các hệ thống có tài nguyên hạn chế nhưng vẫn cần hiệu suất học sâu mạnh mẽ, như các hệ thống nhúng hoặc phần cứng đặc thù như FPGA và ASIC. Các ứng dụng điển hình của BNN bao gồm:
\begin{itemize}
	\item Nhận diện biển báo giao thông: BNN có thể giúp nhận diện các biển báo giao thông trong các hệ thống tự lái hoặc các hệ thống giám sát giao thông.
	
	\item Nhận diện đối tượng trong video: BNN giúp xử lý video trong thời gian thực, nhận diện các đối tượng hoặc hành vi từ các đoạn video.
	
	\item Nhận diện hình ảnh trong IoT devices: Các thiết bị IoT có thể triển khai BNN để nhận diện các hình ảnh hoặc dữ liệu mà không cần yêu cầu quá nhiều bộ nhớ và tính toán.
\end{itemize}

\subsection{Bộ dữ liệu GTSRB (German Traffic Sign Recognition Benchmark)}
Bộ Dữ Liệu GTSRB là một bộ dữ liệu nổi tiếng được sử dụng để huấn luyện và thử nghiệm các mô hình nhận diện biển báo giao thông. Bộ dữ liệu này bao gồm hàng nghìn ảnh biển báo giao thông được chụp tại Đức, và các ảnh này được phân loại thành nhiều nhóm biển báo giao thông khác nhau, ví dụ như biển báo giao nhau, biển báo tốc độ, biển báo cấm, và nhiều loại biển báo khác. GTSRB là một bộ dữ liệu quan trọng trong nghiên cứu nhận diện hình ảnh, đặc biệt là trong các hệ thống tự lái và các ứng dụng giao thông thông minh. \\


\noindent Bộ dữ liệu GTSRB chứa các loại biển báo giao thông khác nhau và được phân chia thành các nhóm:
\begin{itemize}

	\item Biển báo giao nhau: Các biển báo báo hiệu cho người lái xe về các ngã ba, ngã tư.

	\item Biển báo tốc độ: Biển báo giới hạn tốc độ cho phép trong khu vực.

	\item Biển báo cấm: Cấm các hành vi giao thông cụ thể như cấm rẽ trái, rẽ phải hoặc đi vào đường cấm.
\end{itemize}
\noindent Các ảnh trong bộ dữ liệu GTSRB có độ phân giải cao và được gắn nhãn chính xác với các loại biển báo, giúp mô hình học cách phân loại biển báo giao thông một cách hiệu quả.


\section{Huấn luyện tập dữ liệu với Google Colab}
Tải và huấn luyện tệp GSRB trên Google Colab, cho ra được file dạng .npz.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{images/pic11} 
	\caption{Hoàn thành huấn luận trên Google Colab}
\end{figure} 
\section{Chuyển đổi các trọng số và tham số mô hình }
Tệp $gtsrb-gen-binary-weights.py$ được sử dụng để chuyển các trọng số và tham số mô hình từ tệp .npz (trọng số đã huấn luyện từ mô hình) thành các tệp nhị phân và tệp cấu hình C/C++ (config.h) để triển khai mô hình lên phần cứng (FPGA).
\newpage
\subsection{Cấu hình đầu vào}
\begin{lstlisting}[language=Python, numbers=none]
	bnnRoot = "."
	npzFile = bnnRoot + "/gtsrb-1w-1a.npz"
	targetDirBin = bnnRoot + "/cnvW1A1-gtrsb"
	targetDirHLS = bnnRoot + "/cnvW1A1-gtrsb/hw"
\end{lstlisting}
\begin{itemize}
	\item Đầu tiên, tệp \texttt{.npz} chứa các trọng số của mô hình sẽ được tải vào từ đường dẫn \texttt{npzFile}.
	\item Các tệp nhị phân và các tệp HLS (High-Level Synthesis) sẽ được lưu vào các thư mục \texttt{targetDirBin} và \texttt{targetDirHLS} tương ứng.
\end{itemize}

\subsection{Định nghĩa các lớp mạng}
\begin{lstlisting}[language=Python, numbers=none]
	ifm = [32, 30, 14, 12, 5, 3]
	ofm = [30, 28, 12, 10, 3, 1]   
	ifm_ch = [3, 64, 64, 128, 128, 256]
	ofm_ch = [64, 64, 128, 128, 256, 256]   
	filterDim = [3, 3, 3, 3, 3, 3]
\end{lstlisting}
\begin{itemize}
	\item Các thông số này liên quan đến đầu vào (IFM) và đầu ra (OFM) của các lớp chập, bao gồm số lượng kênh đầu vào (ifm\_ch) và số lượng kênh đầu ra (ofm\_ch), cũng như kích thước bộ lọc (filter dimension).
\end{itemize}

\subsection{Đọc tệp .npz và tạo tệp cấu hình config.h}
\begin{lstlisting}[language=Python, numbers=none]
	rHW = BNNWeightReader(npzFile, True)
	config = "/**\n"
	config+= " * Finnthesizer Config-File Generation\n";
	config+= " *\n **/\n\n"
	config+= "#ifndef __LAYER_CONFIG_H_\n#define __LAYER_CONFIG_H_\n\n"
\end{lstlisting}
\begin{itemize}
	\item Trọng số từ tệp .npz được đọc vào bằng cách sử dụng BNNWeightReader. Đây là một lớp có thể được định nghĩa trong thư viện finnthesizer hoặc trong các tệp khác của dự án.
	\item Tệp cấu hình C (config.h) sẽ được tạo ra, chứa các định nghĩa cho các lớp mạng. Đây là phần cấu hình quan trọng khi triển khai mô hình lên phần cứng FPGA, đặc biệt khi sử dụng các công cụ như FINN.
\end{itemize}

\subsection{Lớp Convolutional và Fully Connected}
\begin{lstlisting}[language=Python, numbers=none]
for convl in range(0, 6):
	...
	(w, t) = rHW.readConvBNComplex(...)

	m = BNNProcElemMem(peCount, simdCount, neededWMem, neededTMem, ...)
	m.addMatrix(w, t, paddedW, paddedH)

	config += (printConvDefines("L%d" % convl, filterDim[convl], ifm_ch[convl], ifm[convl], ofm_ch[convl], ofm[convl], simdCount, peCount, neededWMem, neededTMem, WPrecision_integer, 	APrecision_integer, WPrecision_fractional, APrecision_fractional)) + "\n" 

	m.createBinFiles(targetDirBin, str(convl))


for fcl in range(6, 9):
	...
	(w, t) = rHW.readFCBNComplex(...)

	m = BNNProcElemMem(peCount, simdCount, neededWMem, neededTMem, ...)
	m.addMatrix(w, t, paddedW, paddedH)

	config += (printFCDefines("L%d" % fcl, simdCount, peCount, neededWMem, neededTMem, paddedW, paddedH, WPrecision_integer, APrecision_integer, WPrecision_fractional, APrecision_fractional)) + "\n"

	m.createBinFiles(targetDirBin, str(fcl), useThresholds)

\end{lstlisting}

\begin{itemize}
	\item Mỗi lớp chập (Convolutional Layer) được xử lý bằng cách đọc trọng số và ngưỡng (threshold) từ tệp .npz thông qua phương thức readConvBNComplex. \\
	
	Trọng số và ngưỡng được chuyển đổi thành các mảng và lưu vào bộ nhớ, đồng thời tạo các tệp nhị phân (BinFiles) để sử dụng trong lúc chạy mô hình trên phần cứng. \\
	
	Tệp cấu hình (config.h) được cập nhật với các thông tin như số lượng PE, SIMD, bộ nhớ trọng số, bộ nhớ ngưỡng và độ chính xác của các tham số. \\
	
	\item Các lớp fully connected (FC) cũng tương tự như các lớp chập, với quá trình đọc trọng số và ngưỡng, tạo các tệp nhị phân, và cập nhật tệp cấu hình config.h. \\
	
	Các lớp FC có thể khác biệt ở việc không sử dụng ngưỡng trong một số trường hợp (như lớp cuối cùng).
\end{itemize}

\subsection{Lưu tệp cấu hình và tệp nhị phân}
Qua các bước ta thu được các tệp:
\begin{itemize}
	\item Tệp config.h chứa các định nghĩa cấu hình cho các lớp mạng.
	\item Tệp classes.txt chứa các lớp (nhãn) của bộ dữ liệu GTSRB.
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.35]{images/pic12} 
	\caption{Tệp cấu hình và tệp nhị phân}
\end{figure} 

\section{Thiết kế kiến trúc HLS cho CNN}
Thiết kế kiến trúc High-Level Synthesis (HLS) cho một mạng Convolutional Neural Network (CNN) sử dụng các trọng số nhị phân (1-bit weights) và kích hoạt nhị phân (1-bit activations). Mạng này được thiết kế để chạy trên phần cứng, sử dụng mô hình dữ liệu AXI Lite cho việc tải tham số và xử lý dataflow architecture cho việc suy luận hình ảnh (image inference).

\subsection{Chức năng chung}
\begin{itemize}
	\item DoMemInit: Hàm này được sử dụng để khởi tạo các tham số của mạng, bao gồm trọng số (weights) và ngưỡng (thresholds) cho các lớp trong mạng. Các giá trị này được tải vào bộ nhớ theo yêu cầu của người dùng.
	\item DoCompute: Hàm này thực hiện phép toán suy luận trên mạng nơ-ron tích chập, xử lý các đầu vào và tạo ra đầu ra qua các lớp khác nhau của mạng. Nó bao gồm các lớp chập (convolution layers), lớp pool (max pooling), và các lớp kết nối đầy đủ (fully connected layers).
	\item BlackBoxJam: Hàm này là một giao diện cho việc kết nối với phần mềm thông qua giao thức AXI Lite, cho phép điều khiển việc tải tham số và thực hiện suy luận.
\end{itemize}

\subsubsection{Chi tiết mã nguồn sử dụng}
\begin{enumerate}
	\item Các khai báo tĩnh (static) và đối tượng: \\
	
	BinaryWeights và ThresholdsActivation là các lớp mô tả các đối tượng trọng số và ngưỡng. Mỗi lớp tương ứng với một lớp trong mạng nơ-ron và sẽ lưu trữ trọng số hoặc ngưỡng của lớp đó. \\
	
	Các đối tượng như weights0, weights1, threshs0, threshs1 chứa các trọng số và ngưỡng cho mỗi lớp. \\
	
	\item Hàm $paddedSizeHW$: \\
	
	Hàm này tính toán kích thước đã được đệm cho dữ liệu đầu vào sao cho nó phù hợp với kích thước yêu cầu của phần cứng, đảm bảo rằng kích thước của dữ liệu chia hết cho giá trị cần thiết. \\
	
	\item Hàm $DoMemInit$: \\
	
	Hàm này sẽ nhận các tham số xác định lớp (targetLayer), bộ nhớ (targetMem), chỉ mục (targetInd), ngưỡng (targetThresh), và giá trị (val) để lưu trữ giá trị vào bộ nhớ của mạng. Nó sẽ xác định lớp nào và vị trí nào cần được khởi tạo dựa trên tham số truyền vào, sau đó gán giá trị vào bộ nhớ tương ứng. \\
	
	\item Hàm $DoCompute$: \\
	Đây là hàm chính thực hiện phép toán suy luận hình ảnh trên mạng. Các bước chính trong hàm này bao gồm:
	\begin{itemize}
		
\item 	Mem2Stream\_Batch: Chuyển dữ liệu từ bộ nhớ vào các luồng dữ liệu.
	
\item 	StreamingDataWidthConverter\_Batch: Chuyển đổi độ rộng của dữ liệu giữa các luồng.
	
\item 	ConvLayer\_Batch: Áp dụng các lớp tích chập (convolution layers) vào các luồng dữ liệu.
	
\item 	StreamingMaxPool\_Batch: Áp dụng lớp max pooling.
	
\item 	StreamingFCLayer\_Batch: Áp dụng các lớp kết nối đầy đủ (fully connected layers).
	
\item 	Cuối cùng, dữ liệu đầu ra được chuyển từ các luồng vào bộ nhớ.
	
\end{itemize}

\end{enumerate}
\newpage
\section{Tài liệu tham khảo} 
1. Documentation Navigator, 2024, https://www.xilinx.com/support/documentation-navigation/overview.html.  \\ \\
2. Creating a simple Overlay for PYNQ-Z1 board from Vivado HLx, 2017 ,  https://yangtavaresblog.wordpress.com/2017/07/31/creating-a-simple-overlay-for-pynq-z1-board-from-vivado-hlx/. \\ \\
3.  PYNQ: Python productivity for Adaptive Computing platforms, 2022 , https://pynq.readthedocs.io/. \\ \\
4.PYNQ-Z2 Reference Manual v1.1, 2019 , TuL PYNQ-Z2.\\ \\
5. Tutorial: Creating a new Verilog Module Overlay, RogerPease, 2020 , https://discuss.pynq.io/t/tutorial-creating-a-new-verilog-module-overlay/1530. \\ \\
6. Vivado Design Suite User Guide,  AMD XILINX , 2022.


\newpage
\section{Phụ lục}


\end{document}